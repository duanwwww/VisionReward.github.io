<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="description" content="Fine-Grained Multi-Dimensional Human Preference Learning
for Image and Video Generation" />
    <meta name="keywords" content="TODO" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
        VisionReward: Fine-Grained Multi-Dimensional Human Preference Learning
        for Image and Video Generation
    </title>
    <!-- Bulma CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css" rel="stylesheet">

    <!-- FontAwesome Icons -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
    <style>
        /* ÈÄöÁî®Â±Ö‰∏≠Ê†∑Âºè */
        body {
            margin: 0;
            font-family: Arial, sans-serif;
            text-align: center;
        }

        header {
            margin: 20px 0;
        }

        h1 {
            font-size: 2em;
            margin: 10px 0;
        }

        h2 {
            margin: 40px 0 10px;
        }

        a {
            text-decoration: none;
            color: blue;
        }
        
        a:hover {
            text-decoration: underline;
        }

        table {
            width: 80%;
            margin: 20px auto;
            border-collapse: collapse;
            font-size: 16px;
            text-align: center;
            table-layout: fixed;
        }
        th, td {
            padding: 10px;
            vertical-align: middle; /* ÂûÇÁõ¥Â±Ö‰∏≠ */
        }
        th {
            font-weight: bold;
            background-color: #f4f4f4;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        tr:nth-child(odd) {
            background-color: #ffffff;
        }
        tr.image-row {
            background-color: #ffffff; /* ÊâÄÊúâ Image Ë°åÁôΩËâ≤ËÉåÊôØ */
        }
        tr.video-row {
            background-color: #f0f0f0; /* ÊâÄÊúâ Video Ë°åÁÅ∞Ëâ≤ËÉåÊôØ */
        }
        table, th, td {
            border: none; /* ÁßªÈô§ËæπÊ°Ü */
        }

        /* ÂØºËà™Ê†èÊ†∑Âºè */
        .navbar {
            display: flex;
            justify-content: center;
            background-color: #333;
            padding: 10px 0;
            position: sticky;
            top: 0;
            z-index: 1000;
        }

        .navbar a {
            color: white;
            padding: 10px 20px;
            text-decoration: none;
        }

        .navbar a:hover {
            background-color: #575757;
            border-radius: 5px;
        }

        /* È°µÈù¢ÂÜÖÂÆπÂàÜÂå∫Ê†∑Âºè */
        section {
            padding: 20px;
            margin: 20px 0;
            border: 1px solid #ddd;
            border-radius: 5px;
            width: 80%;
            margin-left: auto;
            margin-right: auto;
        }

        .two_column {
            margin: 0;
            font-family: Arial, sans-serif;
            display: flex;
        }
        .column {
            width: 30%;
            padding: 20px;
            box-sizing: border-box;
            border: 1px solid #ddd;
            display: flex;
            flex-direction: column;
            align-items: center;
            font-size: 1em;
        }
        .column h2 {
            margin-bottom: 5px;
            text-align: center;
        }
    </style>
</head>

<body>
    <header style="margin-top: 100px;">
        <h1>VisionReward</h1>
        <p style="font-size: 24px;font-family: 'Times New Roman', Times, serif;">
            Fine-Grained Multi-Dimensional Human Preference Learning for Image and
            Video Generation
        </p>
    </header>
    <div>
        <span>Vision Reward Team</span>
    </div>
    <div>
        <div>
            <span>
                <a href="TODO" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>arXiv</span>
                </a>
            </span>
            <span>
                <a href="https://github.com/xujz18/VisionReward"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                </a>
            </span>
        </div>
    </div>
    
    <div style="display: flex; justify-content: center;">
        <figure style="max-width: 60%; height: auto;">
            <img src="https://duanwwww.github.io/VisionReward.github.io/images/OverView.jpg"
                alt="An overview of the VisionReward and MPO." style="max-width: 100%; height: auto;" />
            <figcaption>An overview of the VisionReward and MPO.</figcaption>
        </figure>
    </div>


    <!-- Ê®™ÂêëÂØºËà™Ê†è -->
    <nav class="navbar">
        <a href="#overview">Overview</a>
        <a href="#intro">Introduction</a>
        <!-- <a href="annotation">Annotation</a> -->
        <!-- <a href="#benchmark">Benchmark</a> -->
        <!-- <a href="#experiments">Experiments</a> -->
        <a href="#case_study">Case Study</a>
        <a href="#citation">Citation</a>
    </nav>

    

    <!-- È°µÈù¢ÂÜÖÂÆπ -->
    <section id="overview">
        <h2 style="font-size: 2em;">Overview</h2>
        
        <p style="max-width: 80%;">
            We present VisionReward, a general strategy to aligning visual generation
            models---both image and video generation---with human preferences through a
            fine-grained and multi-dimensional framework. We decompose human
            preferences in images and videos into multiple dimensions, each
            represented by a series of judgment questions, linearly weighted and
            summed to an interpretable and accurate score. To address the challenges
            of video quality assessment, we systematically analyze various dynamic
            features of videos, which helps VisionReward surpass VideoScore by 17.2%
            and achieve top performance for video preference prediction. Based on
            VisionReward, we develop a multi-objective preference learning algorithm
            that effectively addresses the issue of confounding factors within
            preference data. Our approach significantly outperforms existing image
            and video scoring methods on both machine metrics and human evaluation.
            The models and preference data will be open-sourced.
        </p>
        <div style="display: flex; justify-content: center;">
            <figure style="max-width: 100%; height: auto;">
                <img src="https://duanwwww.github.io/VisionReward.github.io/images/TopDemo.jpg"
                    alt="Samples of VisionReward and Multi-Objective Preference Optimization (MPO) algorithm."
                    style="max-width: 100%; height: auto;" />
            </figure>
        </div>
        <div style="display: flex; justify-content: center; max-width: 100%;">
            <figure style="max-width: 33%; height: auto;">
                <video src="https://duanwwww.github.io/VisionReward.github.io/videos/ori_2.mp4" style="width: 90%; height: auto;" controls>
                </video>
                <figcaption>original
                </figcaption>
            </figure>
            <figure style="max-width: 33%; height: auto;">
                <video src="https://duanwwww.github.io/VisionReward.github.io/videos/videoscore_2.mp4" style="width: 90%; height: auto;" controls>
                </video>
                <figcaption>DPO with VideoScore
                </figcaption>
            </figure>
            <figure style="max-width: 33%; height: auto;">
                <video src="https://duanwwww.github.io/VisionReward.github.io/videos/ours_2.mp4" style="width: 90%; height: auto;" controls>
                </video>
                <figcaption>MPO with VisionReward(Ours)
                </figcaption>
            </figure>
        </div>
        <p, style="text-align: center;">Samples of VisionReward and Multi-Objective Preference Optimization (MPO) algorithm.</p>
    </section>

    <section id="intro">
        <h2 style="font-size: 2em;">Introduction</h2>
        <div style="display: flex; flex-wrap: wrap; gap: 1rem; justify-content: center;">
            <!-- Âç°Áâá 1 -->
            <details style="width: 100%; border: 1px solid #ddd; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.1); overflow: hidden;">
                <summary style="cursor: pointer; padding: 1rem; background-color: #f9f9f9; font-weight: bold; font-size: 1.5em; border-bottom: 1px solid #ddd;">
                    Annotation
                </summary>
                <div style="padding: 1rem;display: flex;flex-wrap: wrap; justify-content: center;">
                    <p style="max-width: 80%;">We design a unified annotation system for both image and video generation, decomposing the factors
                        influencing human preferences. To address the challenges of video evaluation, we incorporate extensive
                        observations of dynamic content in videos into our judgment tasks, such as motion stability or movement
                        quality. The annotation contains 3 million questions for 48k images and 2 million questions for 33k videos.
                    </p>
                    <p style="max-width: 80%;">When evaluating an image or video, human preferences are often a result of the interplay of multiple factors, necessitating a balance among various considerations. To deconstruct human preferences systematically, we develop a fine-grained and multi-dimensional preference decomposition framework.
                    </p>
                    <table>
                        <thead>
                            <tr>
                                <th rowspan="2" style="vertical-align: middle; "><strong>Dimension</strong></th>
                                <th colspan="2"><strong>#Sub-dimension</strong></th>
                                <th colspan="2"><strong>#Checklist</strong></th>
                            </tr>
                            <tr>
                                <th><strong>Image</strong></th>
                                <th><strong>Video</strong></th>
                                <th><strong>Image</strong></th>
                                <th><strong>Video</strong></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Alignment</td>
                                <td>1</td>
                                <td>1</td>
                                <td>1</td>
                                <td>4</td>
                            </tr>
                            <tr>
                                <td>Composition</td>
                                <td>5</td>
                                <td>1</td>
                                <td>13</td>
                                <td>2</td>
                            </tr>
                            <tr>
                                <td>Quality</td>
                                <td>5</td>
                                <td>4</td>
                                <td>14</td>
                                <td>14</td>
                            </tr>
                            <tr>
                                <td>Fidelity</td>
                                <td>5</td>
                                <td>3</td>
                                <td>25</td>
                                <td>9</td>
                            </tr>
                            <tr>
                                <td>Safety & Emotion</td>
                                <td>2</td>
                                <td>1</td>
                                <td>8</td>
                                <td>4</td>
                            </tr>
                            <tr>
                                <td>Stability</td>
                                <td>-</td>
                                <td>5</td>
                                <td>-</td>
                                <td>12</td>
                            </tr>
                            <tr>
                                <td>Dynamic</td>
                                <td>-</td>
                                <td>2</td>
                                <td>-</td>
                                <td>8</td>
                            </tr>
                            <tr>
                                <td>Physics</td>
                                <td>-</td>
                                <td>1</td>
                                <td>-</td>
                                <td>4</td>
                            </tr>
                            <tr>
                                <td>Preservation</td>
                                <td>-</td>
                                <td>2</td>
                                <td>-</td>
                                <td>7</td>
                            </tr>
                            <tr>
                                <td><strong>Total</strong></td>
                                <td><strong>18</strong></td>
                                <td><strong>20</strong></td>
                                <td><strong>61</strong></td>
                                <td><strong>64</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <p><em>Taxonomy of annotation for VisionReward (Ours).</em></p>
                    <table>
                        <thead>
                            <tr>
                                <th><strong>Type</strong></th>
                                <th><strong>Source</strong></th>
                                <th><strong>#Samples</strong></th>
                                <th><strong>#Checklist</strong></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="image-row">
                                <td rowspan="3" style="vertical-align: middle; "><strong>Image</strong></td>
                                <td>ImageRewardDB</td>
                                <td>16K</td>
                                <td>1M</td>
                            </tr>
                            <tr class="image-row">
                                <td>Pick-a-Pic</td>
                                <td>16K</td>
                                <td>1M</td>
                            </tr>
                            <tr class="image-row">
                                <td>HPDv2</td>
                                <td>16K</td>
                                <td>1M</td>
                            </tr>
                            <tr class="video-row">
                                <td rowspan="4" style="vertical-align: middle; "><strong>Video</strong></td>
                                <td>CogVideoX</td>
                                <td>10K</td>
                                <td>0.6M</td>
                            </tr>
                            <tr class="video-row">
                                <td>Open-Sora</td>
                                <td>10K</td>
                                <td>0.6M</td>
                            </tr>
                            <tr class="video-row">
                                <td>VideoCrafter2</td>
                                <td>10K</td>
                                <td>0.6M</td>
                            </tr>
                            <tr class="video-row">
                                <td>Panda-70M</td>
                                <td>3K</td>
                                <td>0.2M</td>
                            </tr>
                        </tbody>
                    </table>
                    <p><em>Statistics of source data and annotation.</em></p>
                    <p style="max-width: 80%;">In our annotation process, we design multiple-choice questions for each dimension, allowing annotators to select the option that best fits the image. Additionally, we further decompose these options into several binary (yes/no) questions, ultimately forming a checklist for evaluating each image or video. This checklist is then utilized for subsequent evaluation systems and reward model training.</p>
                    <p style="font-size: 1.2em; width: 100%;">Examples</p>
                    <!-- <div style="padding: 1rem;display: flex;flex-wrap: wrap; justify-content: center;">
                        <div style="width: 50%;">
                            <div style="width: 100%;">
                                <p>Color Aesthetic (Image) </p>
                            </div>
                            <div class="two_column">
                                <div class="column">
                                    <h2>Options</h2>
                                    <p>Beautiful Colors <i class="far fa-smile" title="good"></i></li>
                                    <p>Ordinary Colors <i class="far fa-meh" title="normal"></i></li>
                                    <p>Ugly Colors <i class="far fa-frown" title="bad"></i></li>
                                </div>
                                <div class="column">
                                    <h2>Checklist</h2>
                                    <p>Are the colors beautiful?</p>
                                    <p>Are the colors not ugly?</p>
                                </div>
                            </div>
                        </div>
                        <div style="width: 50%;">
                            <div style="width: 100%;">
                                <p>Movement Reality (Video) </p>
                            </div>
                            <div class="two_column">
                                <div class="column">
                                    <h2>Options</h2>
                                    <p>Good <i class="far fa-smile" title="good"></i></li>
                                    <p>Normal <i class="far fa-meh" title="normal"></i></li>
                                    <p>Bad <i class="far fa-frown" title="bad"></i></li>
                                </div>
                            
                                <div class="column">
                                    <h2>Checklist</h2>
                                    <p>Is the object's movement completely realistic?</p>
                                    <p>Does the object's movement have no obvious realism issues?</p>
                                </div>
                            </div>
                        </div>
                    </div> -->
                    <table border="1">
                        <!-- Ë°®Â§¥ -->
                        <thead>
                            <tr>
                                <th colspan="2" class="category-title">Color Aesthetic (Image)</th>
                                <th colspan="2" class="category-title">Movement Reality (Video)</th>
                            </tr>
                        </thead>
                        <!-- Ë°®Ê†ºÂÜÖÂÆπ -->
                        <tbody>
                            <tr>
                                <td><strong>Options</strong></td>
                                <td><strong>Checklist</strong></td>
                                <td><strong>Options</strong></td>
                                <td><strong>Checklist</strong></td>
                            </tr>
                            <tr>
                                <td>Beautiful Colors üòä</td>
                                <td>Are the colors beautiful?‚úîÔ∏è</br>br>Are the colors not ugly?‚úîÔ∏è</td>
                                <td>Good üòä</td>
                                <td>Is the object's movement completely realistic?‚úîÔ∏è</br>Does the object's movement have no obvious realism issues?‚úîÔ∏è</td>
                            </tr>
                            <tr>
                                <td>Ordinary Colors üòê</td>
                                <td>Are the colors beautiful?‚ùå</br>br>Are the colors not ugly?‚úîÔ∏è</td>
                                <td>Normal üòê</td>
                                <td>Is the object's movement completely realistic?‚ùå</br>Does the object's movement have no obvious realism issues?‚úîÔ∏è</td>
                            </tr>
                            <tr>
                                <td>Ugly Colors üò¢</td>
                                <td>Are the colors beautiful?‚ùå</br>br>Are the colors not ugly?‚ùå</td>
                                <td>Bad üò¢</td>
                                <td>Is the object's movement completely realistic?‚ùå</br>Does the object's movement have no obvious realism issues?‚ùå</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </details>
            
            <!-- Âç°Áâá 2 -->
            <details style="width: 100%; border: 1px solid #ddd; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.1); overflow: hidden;">
                <summary style="cursor: pointer; padding: 1rem; background-color: #f9f9f9; font-weight: bold; font-size: 1.1rem; border-bottom: 1px solid #ddd;">
                    Â≠êÊ†áÈ¢ò 2
                </summary>
                <div style="padding: 1rem;">
                    <p style="margin: 0 0 1rem;">ËøôÊòØÂ≠êÁ´†ËäÇ 2 ÁöÑÂÜÖÂÆπ„ÄÇËøôÈÉ®ÂàÜÂèØ‰ª•Êâ©Â±ï‰∏∫ÂÖ∂‰ªñÂΩ¢ÂºèÁöÑÂÜÖÂÆπÂ±ïÁ§∫„ÄÇ</p>
                    <a href="#" style="text-decoration: none; color: #007bff;">Êü•ÁúãËØ¶ÊÉÖ ‚Üí</a>
                </div>
            </details>
    
            <!-- Âç°Áâá 3 -->
            <details style="width: 100%; border: 1px solid #ddd; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.1); overflow: hidden;">
                <summary style="cursor: pointer; padding: 1rem; background-color: #f9f9f9; font-weight: bold; font-size: 1.1rem; border-bottom: 1px solid #ddd;">
                    Â≠êÊ†áÈ¢ò 3
                </summary>
                <div style="padding: 1rem;">
                    <p style="margin: 0 0 1rem;">ËøôÊòØÂ≠êÁ´†ËäÇ 3 ÁöÑÂÜÖÂÆπ„ÄÇÂèØ‰ª•ÊòØÊñáÂ≠ó„ÄÅÂõæÁâá„ÄÅÈìæÊé•ÊàñÂÖ∂‰ªñÂÜÖÂÆπ„ÄÇ</p>
                    <a href="#" style="text-decoration: none; color: #007bff;">Êü•ÁúãËØ¶ÊÉÖ ‚Üí</a>
                </div>
            </details>
        </div>
        
        <h3 >annotation</h3>
        table&questions
        <h3>model</h3>
        scoring examples
        <h3>examples</h3>
        <h3>mpo</h3>
        figure&explanations
    </section>

    <!-- <section id="annotation">
        <h2 style="font-size: 1.5em;">Annotation</h2>
        <p>We design a unified annotation system for both image and video generation, decomposing the factors
            influencing human preferences. To address the challenges of video evaluation, we incorporate extensive
            observations of dynamic content in videos into our judgment tasks, such as motion stability or movement
            quality. The annotation contains 3 million questions for 48k images and 2 million questions for 33k videos.
        </p> -->
        <!-- <div style="display: flex; justify-content: space-between;">
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/attributes_annotation_distribution_image.jpg"
                        alt="Text-to-image" style="width: 100%; height: auto;">
                    <figcaption>Text-to-image</figcaption>
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/attributes_annotation_distribution_video.jpg"
                        alt="Text-to-video" style="width: 100%; height: auto;">
                    <figcaption>Text-to-video</figcaption>
                </figure>
            </div>

        </div> -->
        <!-- <p>Annotation statistics of different sub-dimensions.</p>
        <table border="1" cellpadding="5" cellspacing="0"
            style="width: 80%; margin: 20px auto; border-collapse: collapse; font-size: 16px;">
            <thead>
                <tr>
                    <th rowspan="2"><strong>Dimension</strong></th>
                    <th colspan="2"><strong>#Sub-dimension</strong></th>
                    <th colspan="2"><strong>#Checklist</strong></th>
                </tr>
                <tr>
                    <th><strong>Image</strong></th>
                    <th><strong>Video</strong></th>
                    <th><strong>Image</strong></th>
                    <th><strong>Video</strong></th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Alignment</td>
                    <td>1</td>
                    <td>1</td>
                    <td>1</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>Composition</td>
                    <td>5</td>
                    <td>1</td>
                    <td>13</td>
                    <td>2</td>
                </tr>
                <tr>
                    <td>Quality</td>
                    <td>5</td>
                    <td>4</td>
                    <td>14</td>
                    <td>14</td>
                </tr>
                <tr>
                    <td>Fidelity</td>
                    <td>5</td>
                    <td>3</td>
                    <td>25</td>
                    <td>9</td>
                </tr>
                <tr>
                    <td>Safety & Emotion</td>
                    <td>2</td>
                    <td>1</td>
                    <td>8</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>Stability</td>
                    <td>-</td>
                    <td>5</td>
                    <td>-</td>
                    <td>12</td>
                </tr>
                <tr>
                    <td>Dynamic</td>
                    <td>-</td>
                    <td>2</td>
                    <td>-</td>
                    <td>8</td>
                </tr>
                <tr>
                    <td>Physics</td>
                    <td>-</td>
                    <td>1</td>
                    <td>-</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>Preservation</td>
                    <td>-</td>
                    <td>2</td>
                    <td>-</td>
                    <td>7</td>
                </tr>
                <tr>
                    <td><strong>Total</strong></td>
                    <td><strong>18</strong></td>
                    <td><strong>20</strong></td>
                    <td><strong>61</strong></td>
                    <td><strong>64</strong></td>
                </tr>
            </tbody>
        </table>
        <p><em>Taxonomy of annotation for VisionReward (Ours).</em></p>
        <table border="1" cellpadding="10" cellspacing="0"
            style="width: 80%; margin: 20px auto; border-collapse: collapse;font-size: 16px;">
            <thead>
                <tr>
                    <th><strong>Type</strong></th>
                    <th><strong>Source</strong></th>
                    <th><strong>#Samples</strong></th>
                    <th><strong>#Checklist</strong></th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td rowspan="3"><strong>Image</strong></td>
                    <td>ImageRewardDB</td>
                    <td>16K</td>
                    <td>1M</td>
                </tr>
                <tr>
                    <td>Pick-a-Pic</td>
                    <td>16K</td>
                    <td>1M</td>
                </tr>
                <tr>
                    <td>HPDv2</td>
                    <td>16K</td>
                    <td>1M</td>
                </tr>
                <tr>
                    <td rowspan="4"><strong>Video</strong></td>
                    <td>CogVideoX</td>
                    <td>10K</td>
                    <td>0.6M</td>
                </tr>
                <tr>
                    <td>Open-Sora</td>
                    <td>10K</td>
                    <td>0.6M</td>
                </tr>
                <tr>
                    <td>VideoCrafter2</td>
                    <td>10K</td>
                    <td>0.6M</td>
                </tr>
                <tr>
                    <td>Panda-70M</td>
                    <td>3K</td>
                    <td>0.2M</td>
                </tr>
            </tbody>
        </table>
        <p><em>Statistics of source data and annotation.</em></p> -->


    </section>

    <!-- <section id="benchmark">
        <h2 style="font-size: 1.5em;">MonetBench: Multi-Dimensional Benchmark</h2>
        <p>To establish a comprehensive evaluation benchmark for both image and video generation, we construct
            Monet-Bench, which contains two specialized test sets: Image-MonetBench and Video-MonetBench. The following
            table shows content and challenge categories for image and video domains. </p>
        <table border="1" cellpadding="5" cellspacing="0"
            style="width: 80%; margin: 20px auto; border-collapse: collapse; font-size: 16px;">
            <thead>
                <tr>
                    <th><strong>Type</strong></th>
                    <th><strong>Image</strong></th>
                    <th><strong>Video</strong></th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Content</strong></td>
                    <td>People, Objects, Animals,Architecture, Landscape,Vehicles, Plants, Food,Others, Scenes</td>
                    <td>Story, Human Activity,Artificial Scene, Others,Natural Animal ActivityPhysical Phenomena</td>
                </tr>
                <tr>
                    <td><strong>Challenge</strong></td>
                    <td>Unreal, Style, History,Fine-grained Detail,Color, Famous Character,Normal, Famous
                        Places,Writing, Complex Combo,Positional, Counting,</td>
                    <td>Material, Angle and Lens,Emotional Expression,Color/Tone, Surreal,World Knowledge,Special
                        Effects, Text,Spatial Relationship,Camera Movement,Logical Consistency,Style, Temporal Speed
                    </td>
                </tr>
            </tbody>
        </table>
        <p><em>Content and Challenge Categories for Image and Video</em></p>
        <div style="display: flex; justify-content: space-between;">
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/content_type_counts_optimized.png"
                        alt="Content(image)" style="width: 100%; height: auto;">
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/content_video.png"
                        alt="Content(video)" style="width: 100%; height: auto;">
                </figure>
            </div>
        </div>
        <div style="display: flex; justify-content: space-between;">
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/challenge_type_counts_optimized.png"
                        alt="Challenge(image)" style="width: 100%; height: auto;">
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/challenge_video.png"
                        alt="Challenge(video)" style="width: 100%; height: auto;">
                </figure>
            </div>
        </div>
    </section> -->

    <section id="experiments">
        <h2  style="font-size: 1.5em;">Experiments</h2>
        <table border="1" cellpadding="10" cellspacing="0"
            style="width: 80%; margin: 20px auto; border-collapse: collapse;font-size: 16px;">
            <thead>
                <tr>
                    <th rowspan="3"><strong>Method</strong></th>
                    <th colspan="3"><strong>Image</strong></th>
                    <th colspan="4"><strong>Video</strong></th>
                </tr>
                <tr>
                    <th rowspan="2"><strong>HPDv2</strong></th>
                    <th colspan="2"><strong>MonetBench</strong></th>
                    <th colspan="2"><strong>GenAI-Bench</strong></th>
                    <th colspan="2"><strong>MonetBench</strong></th>
                </tr>
                <tr>
                    <th><strong>tau*</strong></th>
                    <th><strong>diff**</strong></th>
                    <th><strong>tau</strong></th>
                    <th><strong>diff</strong></th>
                    <th><strong>tau</strong></th>
                    <th><strong>diff</strong></th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td colspan="8" style="font-style: italic; color: #6a1b9a; text-align: left;"><strong>task-specific
                            discriminative models</strong></td>
                </tr>
                <tr>
                    <td>ImageReward</td>
                    <td>74.0</td>
                    <td>48.8</td>
                    <td>56.5</td>
                    <td>48.4</td>
                    <td>72.1</td>
                    <td>55.8</td>
                    <td>58.4</td>
                </tr>
                <tr>
                    <td>PickScore</td>
                    <td>79.8</td>
                    <td>49.8</td>
                    <td>57.6</td>
                    <td><u>52.4</u></td>
                    <td><u>75.4</u></td>
                    <td>57.7</td>
                    <td>61.6</td>
                </tr>
                <tr>
                    <td>HPSv2</td>
                    <td><u>83.3</u></td>
                    <td>48.4</td>
                    <td>55.6</td>
                    <td>49.3</td>
                    <td>73.0</td>
                    <td>59.3</td>
                    <td>62.5</td>
                </tr>
                <tr>
                    <td colspan="8" style="font-style: italic; color: #6a1b9a;text-align: left;"><strong>generative
                            models</strong></td>
                </tr>
                <tr>
                    <td>GPT-4o</td>
                    <td>77.5</td>
                    <td>38.9</td>
                    <td>52.7</td>
                    <td>41.8</td>
                    <td>54.3</td>
                    <td>45.7</td>
                    <td>48.3</td>
                </tr>
                <tr>
                    <td>Gemini</td>
                    <td>60.7</td>
                    <td>27.4</td>
                    <td>55.1</td>
                    <td>46.9</td>
                    <td>61.7</td>
                    <td>52.2</td>
                    <td>56.8</td>
                </tr>
                <tr>
                    <td>VQAScore</td>
                    <td>69.7</td>
                    <td>49.4</td>
                    <td>56.5</td>
                    <td>45.2</td>
                    <td>68.0</td>
                    <td>56.1</td>
                    <td>59.5</td>
                </tr>
                <tr>
                    <td>VideoScore</td>
                    <td>76.8</td>
                    <td>45.8</td>
                    <td>52.5</td>
                    <td>47.8</td>
                    <td>71.4</td>
                    <td>49.1</td>
                    <td>54.9</td>
                </tr>
                <tr>
                    <td><strong>VisionReward (Ours)</strong></td>
                    <td><strong>81.7</strong></td>
                    <td><u><strong>51.8</strong></u></td>
                    <td><u><strong>59.5</strong></u></td>
                    <td><strong>51.8</strong></td>
                    <td><strong>74.4</strong></td>
                    <td><u><strong>64.0</strong></u></td>
                    <td><u><strong>72.1</strong></u></td>
                </tr>
            </tbody>
        </table>
        <p><em>Preference accuracy on multiple dataset. <strong>Bold</strong> denotes the best score within the
                generative models, while <u>underline</u> signifies the best score among all categories. Tau* means
                taking account of ties, and diff** means dropping ties in labels (we drop ties both in labels and
                responses for GPT-4o and Gemini in diff** because too many ties are given by them).</em></p>
        <table border="1" cellpadding="5" cellspacing="0"
            style="width: 80%; margin: 20px auto; border-collapse: collapse; font-size: 16px;">
            <thead>
                <tr>
                    <th rowspan="2"><strong>Method</strong></th>
                    <th colspan="4"><strong>Image</strong></th>
                    <th colspan="4"><strong>Video</strong></th>
                </tr>
                <tr>
                    <th><strong>Composition</strong></th>
                    <th><strong>Quality</strong></th>
                    <th><strong>Fidelity</strong></th>
                    <th><strong>Safety & Emotion</strong></th>
                    <th><strong>Stability</strong></th>
                    <th><strong>Dynamic</strong></th>
                    <th><strong>Physics</strong></th>
                    <th><strong>Preservation</strong></th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>LLaVa<sup>*</sup></td>
                    <td>59.9</td>
                    <td>65.7</td>
                    <td><strong>80.9</strong></td>
                    <td>64.4</td>
                    <td>52.5</td>
                    <td>53.8</td>
                    <td>50.6</td>
                    <td>47.5</td>
                </tr>
                <tr>
                    <td>CogVLM2</td>
                    <td>65.8</td>
                    <td>67.1</td>
                    <td>53.1</td>
                    <td>74.7</td>
                    <td>49.3</td>
                    <td>57.1</td>
                    <td>51.2</td>
                    <td>47.8</td>
                </tr>
                <tr>
                    <td>GPT-4o</td>
                    <td>73.1</td>
                    <td>62.7</td>
                    <td>61.9</td>
                    <td>70.1</td>
                    <td>57.9</td>
                    <td>69.1</td>
                    <td><strong>62.4</strong></td>
                    <td>58.8</td>
                </tr>
                <tr>
                    <td>Gemini</td>
                    <td>69.4</td>
                    <td>59.9</td>
                    <td>59.7</td>
                    <td>74.9</td>
                    <td>58.1</td>
                    <td>71.1</td>
                    <td>58.1</td>
                    <td>59.6</td>
                </tr>
                <tr>
                    <td><strong>VisionReward (Ours)</strong></td>
                    <td><strong>78.8</strong></td>
                    <td><strong>81.1</strong></td>
                    <td><strong>80.9</strong></td>
                    <td><strong>83.9</strong></td>
                    <td><strong>62.8</strong></td>
                    <td><strong>72.6</strong></td>
                    <td>53.1</td>
                    <td><strong>68.0</strong></td>
                </tr>
            </tbody>
        </table>
        <p><em>Accuracy of VisionReward (Ours) and other vision-language models (VLMs) on vision quality questions
                constructed from our annotation.* We test LLaVA-v1.5-7B for image and LLava-Next-Video-34B for
                video.</em></p>

        <!-- <div style="display: flex; justify-content: space-between; flex-wrap: wrap;">
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/exp_Overall_score.jpg"
                        alt="Overall Score" style="width: 100%; height: auto;">
                    <figcaption>Overall Score</figcaption>
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/exp_Composition_score.jpg"
                        alt="Composition Score" style="width: 100%; height: auto;">
                    <figcaption>Composition Score</figcaption>
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/exp_Fidelity_score.jpg"
                        alt="Fidelity Score" style="width: 100%; height: auto;">
                    <figcaption>Fidelity Score</figcaption>
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/exp_Alignment_score.jpg"
                        alt="Alignment Score" style="width: 100%; height: auto;">
                    <figcaption>Alignment Score</figcaption>
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/exp_Quality_score.jpg"
                        alt="Quality Score" style="width: 100%; height: auto;">
                    <figcaption>Quality Score</figcaption>
                </figure>
            </div>
            <div style="display: flex; justify-content: center;width: 48%;height: auto;">
                <figure>
                    <img src="https://duanwwww.github.io/VisionReward.github.io/images/exp_Safety_and_Emotion_score.jpg"
                        alt="Safety&Emotion Score" style="width: 100%; height: auto;">
                    <figcaption>Safety&Emotion Score</figcaption>
                </figure>
            </div>
        </div> -->
    </section>

    <section id="case_study">
        <h2  style="font-size: 1.5em;">Case Study</h2>
        <div style="display: flex; justify-content: center;">
            <figure style="max-width: 60%; height: auto;">
                <img src="https://duanwwww.github.io/VisionReward.github.io/images/mpo_case_image.jpg"
                    alt="Qualitative result of MPO in text-to-image." style="max-width: 100%; height: auto;" />
                <figcaption>Qualitative result of MPO in text-to-image.</figcaption>
            </figure>
        </div>
        <!-- <div style="display: flex; justify-content: center;">
            <figure style="max-width: 60%; height: auto;">
                <img src="https://duanwwww.github.io/VisionReward.github.io/images/dpo_case_1.jpg"
                    alt="SQualitative result of MPO in text-to-video." style="max-width: 100%; height: auto;" />
                <figcaption>Qualitative result of MPO in text-to-video.</figcaption>
            </figure>
        </div>
        <div style="display: flex; justify-content: center;">
            <figure style="max-width: 60%; height: auto;">
                <img src="https://duanwwww.github.io/VisionReward.github.io/images/dpo_case_2.jpg"
                    alt="Qualitative result of MPO in text-to-video." style="max-width: 100%; height: auto;" />
                <figcaption>Qualitative result of MPO in text-to-video.</figcaption>
            </figure>
        </div> -->
    </section>

    <section id="citation">
        <h2  style="font-size: 1.5em;">Citation</h2>
        <p>VisionReward</p>
    </section>
</body>

</html>